{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "809bab01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================\n",
    "# 0. Install/Import\n",
    "# ==============================\n",
    "#!pip install google-generativeai python-dotenv tqdm pandas --quiet\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from pathlib import Path\n",
    "from IPython.display import display\n",
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "import time\n",
    "from tqdm.notebook import tqdm\n",
    "import google.generativeai as genai\n",
    "\n",
    "# ==============================\n",
    "# 1. ENVIRONMENT SETUP\n",
    "# ==============================\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"GEMINI_API_KEY\")\n",
    "if not api_key:\n",
    "    raise ValueError(\"GEMINI_API_KEY not set in your .env file!\")\n",
    "genai.configure(api_key=api_key)\n",
    "model = genai.GenerativeModel(\"gemini-2.5-flash-preview-05-20\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0cc65f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_PROMPT = \"\"\"\n",
    "You are a medical data parser. Given a block of Taiwanese hospital lab report text, extract each individual test into a structured JSON object for API use.\n",
    "Remove all names of patients, doctors, and lab staff for privacy.\n",
    "Convert all dates from ROC (民國) to Gregorian (西元) format and merge with times as YYYYMMDD-HHMMSS.\n",
    "For each lab test, extract:\n",
    "patient_id (病歷號)\n",
    "lab_order_id (單據號碼)\n",
    "encounter_id (門診序號)\n",
    "department (科別)\n",
    "specimen (檢體別)\n",
    "lab_report_type (⊙...⊙ section)\n",
    "diagnosis_codes (all ICD codes listed)\n",
    "dates: { requested, collected, received, reported }\n",
    "tests: { test_name, value, unit, reference_range, interpretation }\n",
    "If a test value has \"H\" or \"L\", set interpretation as \"elevated\" or \"decreased\", otherwise \"normal\" or use existing qualitative result (e.g., Reactive).\n",
    "Return a JSON array. Do NOT include or return any names or national IDs.\n",
    "Output only the JSON.\n",
    "[\n",
    "  {\n",
    "    \"name\": \"parse_lab_report\",\n",
    "    \"description\": \"Parse a Taiwanese hospital lab report into structured JSON objects.\",\n",
    "    \"parameters\": {\n",
    "      \"type\": \"object\",\n",
    "      \"properties\": {\n",
    "        \"reports\": {\n",
    "          \"type\": \"array\",\n",
    "          \"description\": \"List of parsed lab report entries.\",\n",
    "          \"items\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "              \"patient_id\": {\n",
    "                \"type\": \"string\"\n",
    "              },\n",
    "              \"lab_order_id\": {\n",
    "                \"type\": \"string\"\n",
    "              },\n",
    "              \"encounter_id\": {\n",
    "                \"type\": \"string\"\n",
    "              },\n",
    "              \"department\": {\n",
    "                \"type\": \"string\"\n",
    "              },\n",
    "              \"specimen\": {\n",
    "                \"type\": \"string\"\n",
    "              },\n",
    "              \"lab_report_type\": {\n",
    "                \"type\": \"string\"\n",
    "              },\n",
    "              \"diagnosis_codes\": {\n",
    "                \"type\": \"array\",\n",
    "                \"items\": {\n",
    "                  \"type\": \"string\"\n",
    "                }\n",
    "              },\n",
    "              \"dates\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                  \"requested\": {\n",
    "                    \"type\": \"string\"\n",
    "                  },\n",
    "                  \"collected\": {\n",
    "                    \"type\": \"string\"\n",
    "                  },\n",
    "                  \"received\": {\n",
    "                    \"type\": \"string\"\n",
    "                  },\n",
    "                  \"reported\": {\n",
    "                    \"type\": \"string\"\n",
    "                  }\n",
    "                }\n",
    "              },\n",
    "              \"tests\": {\n",
    "                \"type\": \"array\",\n",
    "                \"items\": {\n",
    "                  \"type\": \"object\",\n",
    "                  \"properties\": {\n",
    "                    \"test_name\": {\n",
    "                      \"type\": \"string\"\n",
    "                    },\n",
    "                    \"value\": {\n",
    "                      \"type\": \"string\"\n",
    "                    },\n",
    "                    \"unit\": {\n",
    "                      \"type\": \"string\"\n",
    "                    },\n",
    "                    \"reference_range\": {\n",
    "                      \"type\": \"string\"\n",
    "                    },\n",
    "                    \"interpretation\": {\n",
    "                      \"type\": \"string\"\n",
    "                    }\n",
    "                  }\n",
    "                }\n",
    "              }\n",
    "            }\n",
    "          }\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "]\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "239bc3f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. UTILS\n",
    "# ==============================\n",
    "\n",
    "def split_lab_blocks(text):\n",
    "    # Split at ~I; or ~IL2X3; (delimiters)\n",
    "    blocks = re.split(r'(?<=\\n)(~I;|~IL2X3;)', text)\n",
    "    out_blocks = []\n",
    "    for i in range(1, len(blocks), 2):\n",
    "        block = blocks[i] + blocks[i+1]\n",
    "        if len(block.strip()) > 100:\n",
    "            out_blocks.append(block.strip())\n",
    "    return out_blocks\n",
    "\n",
    "def extract_reports(text):\n",
    "    \"\"\"\n",
    "    Robustly extracts the 'reports' list from various possible Gemini output structures.\n",
    "    Supports:\n",
    "    - [ {...}, {...} ]\n",
    "    - { \"reports\": [...] }\n",
    "    - { \"parameters\": { \"reports\": [...] } }\n",
    "    - { ... } (single object that is a report)\n",
    "    Returns a list of report dicts or [].\n",
    "    \"\"\"\n",
    "    # Remove markdown/code block formatting if present\n",
    "    text = text.strip()\n",
    "    if text.startswith(\"```\"):\n",
    "        text = re.sub(r\"^```[a-z]*\\n?\", \"\", text)\n",
    "        text = re.sub(r\"\\n?```$\", \"\", text)\n",
    "        text = text.strip()\n",
    "    try:\n",
    "        data = json.loads(text)\n",
    "    except Exception:\n",
    "        # Try to recover from malformed JSON (not recommended but fallback)\n",
    "        try:\n",
    "            # Remove trailing commas (common LLM error)\n",
    "            text = re.sub(r\",(\\s*[}\\]])\", r\"\\1\", text)\n",
    "            data = json.loads(text)\n",
    "        except Exception:\n",
    "            raise ValueError(\"No valid JSON object found.\")\n",
    "    # Handle various wrapping\n",
    "    if isinstance(data, list):\n",
    "        return data\n",
    "    if isinstance(data, dict):\n",
    "        if \"parameters\" in data and \"reports\" in data[\"parameters\"]:\n",
    "            return data[\"parameters\"][\"reports\"]\n",
    "        if \"reports\" in data:\n",
    "            return data[\"reports\"]\n",
    "        # If single dict looks like a report (has keys)\n",
    "        if \"patient_id\" in data:\n",
    "            return [data]\n",
    "    return []\n",
    "\n",
    "\n",
    "def flatten_reports(json_data):\n",
    "    flat_rows = []\n",
    "    reports = json_data.get(\"reports\", [])\n",
    "    for report in reports:\n",
    "        parent = {\n",
    "            \"patient_id\": report.get(\"patient_id\", \"\"),\n",
    "            \"lab_order_id\": report.get(\"lab_order_id\", \"\"),\n",
    "            \"encounter_id\": report.get(\"encounter_id\", \"\"),\n",
    "            \"department\": report.get(\"department\", \"\"),\n",
    "            \"specimen\": report.get(\"specimen\", \"\"),\n",
    "            \"lab_report_type\": report.get(\"lab_report_type\", \"\"),\n",
    "            \"diagnosis_codes\": \";\".join(report.get(\"diagnosis_codes\", [])),\n",
    "            \"requested\": report.get(\"dates\", {}).get(\"requested\", \"\"),\n",
    "            \"collected\": report.get(\"dates\", {}).get(\"collected\", \"\"),\n",
    "            \"received\": report.get(\"dates\", {}).get(\"received\", \"\"),\n",
    "            \"reported\": report.get(\"dates\", {}).get(\"reported\", \"\"),\n",
    "        }\n",
    "        tests = report.get(\"tests\", [])\n",
    "        for test in tests:\n",
    "            row = parent.copy()\n",
    "            row.update({\n",
    "                \"test_name\": test.get(\"test_name\", \"\"),\n",
    "                \"value\": test.get(\"value\", \"\"),\n",
    "                \"unit\": test.get(\"unit\", \"\"),\n",
    "                \"reference_range\": test.get(\"reference_range\", \"\"),\n",
    "                \"interpretation\": test.get(\"interpretation\", \"\"),\n",
    "            })\n",
    "            flat_rows.append(row)\n",
    "    return flat_rows\n",
    "\n",
    "def call_gemini_api(block, model, sys_inst):\n",
    "    prompt = sys_inst.strip() + \"\\n\\n\" + block.strip()\n",
    "    try:\n",
    "        response = model.generate_content(\n",
    "            prompt,\n",
    "            generation_config=genai.types.GenerationConfig(temperature=0.3),\n",
    "            stream=False,\n",
    "        )\n",
    "        return response.text\n",
    "    except Exception as e:\n",
    "        print(f\"[ERROR] Gemini API error: {e}\")\n",
    "        return None\n",
    "\n",
    "def process_lab_txt_file(input_path, output_json_path, output_csv_path, model, batch_size=5, sleep_s=1):\n",
    "    with open(input_path, encoding=\"utf-8\") as f:\n",
    "        raw = f.read()\n",
    "    blocks = split_lab_blocks(raw)\n",
    "    print(f\"[INFO] Total lab sheets found: {len(blocks)}\")\n",
    "\n",
    "    merged_reports = []\n",
    "    raw_gemini_outputs = []\n",
    "    total_batches = (len(blocks) + batch_size - 1) // batch_size\n",
    "    with tqdm(total=total_batches, desc=\"Gemini batches\") as bar:\n",
    "        for i in range(0, len(blocks), batch_size):\n",
    "            batch = blocks[i:i+batch_size]\n",
    "            for idx, block in enumerate(batch):\n",
    "                output = call_gemini_api(block, model, SYSTEM_PROMPT)\n",
    "                # --- Save raw Gemini reply regardless of parse ---\n",
    "                if output is not None:\n",
    "                    raw_gemini_outputs.append(\n",
    "                        f\"\\n=== Gemini Reply for Block {i+idx+1} ===\\n{output.strip()}\\n\"\n",
    "                    )\n",
    "                    try:\n",
    "                        reports = extract_reports(output)\n",
    "                        merged_reports.extend(reports)\n",
    "                    except Exception as e:\n",
    "                        print(f\"[ERROR] Failed to parse Gemini output: {e}\")\n",
    "                else:\n",
    "                    raw_gemini_outputs.append(\n",
    "                        f\"\\n=== Gemini Reply for Block {i+idx+1} ===\\n[API returned None]\\n\"\n",
    "                    )\n",
    "                time.sleep(sleep_s)  # Avoid rate limit\n",
    "            bar.update(1)\n",
    "\n",
    "    # Save raw Gemini replies to TXT for debug\n",
    "    raw_txt_path = output_json_path.parent / (output_json_path.stem.replace(\"_parsed\", \"_gemini_raw_replies\") + \".txt\")\n",
    "    with open(raw_txt_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.writelines(raw_gemini_outputs)\n",
    "    print(f\"[INFO] Saved raw Gemini replies: {raw_txt_path}\")\n",
    "\n",
    "    # Save merged JSON\n",
    "    with open(output_json_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump({\"reports\": merged_reports}, f, ensure_ascii=False, indent=2)\n",
    "    print(f\"[INFO] Saved merged JSON: {output_json_path}\")\n",
    "\n",
    "    # Flatten and save CSV\n",
    "    flat_rows = flatten_reports({\"reports\": merged_reports})\n",
    "    df = pd.DataFrame(flat_rows)\n",
    "    df.to_csv(output_csv_path, index=False)\n",
    "    print(f\"[INFO] Saved flattened CSV: {output_csv_path}\")\n",
    "    return df\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4f29e6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Found 1 txt files: ['labs.txt']\n",
      "[INFO] Processing: labs.txt\n",
      "[INFO] Total lab sheets found: 26\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1c0a9ea0df545739a3b88fcc67a952d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Gemini batches:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 4. EXECUTION BLOCK\n",
    "# ==============================\n",
    "\n",
    "input_dir = Path(\"./input\")\n",
    "output_dir = Path(\"./output\")\n",
    "output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "input_files = list(input_dir.glob(\"*.txt\"))\n",
    "print(f\"[INFO] Found {len(input_files)} txt files: {[f.name for f in input_files]}\")\n",
    "if not input_files:\n",
    "    print(\"[INFO] No .txt files found in input directory.\")\n",
    "else:\n",
    "    input_path = input_files[0]\n",
    "    output_json_path = output_dir / (input_path.stem + \"_parsed.json\")\n",
    "    output_csv_path = output_dir / (input_path.stem + \"_parsed.csv\")\n",
    "    print(f\"[INFO] Processing: {input_path.name}\")\n",
    "    df = process_lab_txt_file(input_path, output_json_path, output_csv_path, model)\n",
    "    display(df.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
